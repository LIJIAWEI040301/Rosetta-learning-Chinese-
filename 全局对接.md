# Rosetta 全局对接流程

## 1. 结构准备

以 AlphaFold 获得的结构为例，如是来自于实验方法的结构，需要去掉其他所有配体，只保留蛋白质骨架。

---

## 2. 结构准备（Relax）

保存下列内容到 `flag_relax` 文件：

```
# 每个结构生成两个 relaxed 模型
-nstruct 2

# 将 backbone 限制在初始构象附近
-relax:constrain_relax_to_start_coords

# 不进行 constraint ramping
-relax:ramp_constraints false

# 增加侧链构象采样
-ex1
-ex2

# 使用输入结构的侧链构象
-use_input_sc

# 翻转 H、N、Q 以优化氢键
-flip_HNQ

# 优化氢原子的位置
-no_optH false
```

保存下列内容到 `relax.sh` 文件：

```bash
#!/bin/bash

# 设置输入目录
INPUT_DIR=/root/autodl-tmp/dk1/pdb

# 设置输出目录
OUTPUT_BASE=/root/autodl-tmp/dk1/relax_outputs
mkdir -p "$OUTPUT_BASE"

# 设置 flag 文件路径（与脚本放一起）
FLAG_FILE=flag_relax

# 处理 a.pdb
INPUT_A=${INPUT_DIR}/a.pdb
OUTPUT_A=${OUTPUT_BASE}/a_relax
mkdir -p "$OUTPUT_A"

echo "Relaxing a.pdb..."
relax.default.linuxgccrelease \
    -in:file:s "$INPUT_A" \
    -out:path:all "$OUTPUT_A" \
    @"$FLAG_FILE"

# 处理 b.pdb(如果同时处理两个蛋白就加上这个)
#INPUT_B=${INPUT_DIR}/b.pdb
#OUTPUT_B=${OUTPUT_BASE}/b_relax
#mkdir -p "$OUTPUT_B"

#echo "Relaxing b.pdb..."
#relax.default.linuxgccrelease \
#    -in:file:s "$INPUT_B" \
#    -out:path:all "$OUTPUT_B" \
#    @"$FLAG_FILE"

echo "Relaxation completed for both a.pdb and b.pdb!"
```

> **注意：** 将上述路径修改为你的实际文件路径  
> **运行脚本开始准备**  
> **运行时间参考：** 一条长约 600 的蛋白，单线程需要运行约 3~4 小时  
> **如果同时准备多个蛋白，可两个并行**

---

## 3. 将两条蛋白放在一起

### 使用 Windows 版 PyMOL 方法：

1. 打开其中一个 pdb 文件  
2. `File -> Open` 打开另一个 pdb 文件  
3. 点击右下角面板，将 Mouse Mode 切换为 `3-Button Viewing`  
4. `Shift + 鼠标左键` 旋转  
5. `Shift + 鼠标滚轮` 拖动  
6. 将两个蛋白调整到靠近但不重叠的状态  

### Rosetta 的输入要求：

需要将两个蛋白保存到一起，但保存为两条链。

### 命令行方法：

```pymol
# 设置链 ID（可自定义，也可用 A 和 B）
alter 64ar_0001, chain='A'
alter c6002, chain='B'

# 更新内部结构
sort

# 合并两个对象为一个新对象
create merged_protein, 64ar_0001 or c6002

# 保存为一个 PDB 文件
save merged_protein.pdb, merged_protein
```

---

## 4. 设置对接参数

保存为 `flag_global_docking` 文件：

```
# 输入结构
-in:file:s input_files/a_0001_b_0002.pdb

# 使用输入结构的侧链构象
-unboundrot input_files/a_0001_b_0002.pdb

# 对接链对
-partners A_B

# 对接扰动
-dock_pert 3 8

# 全局对接参数
-spin
-randomize1
-randomize2

# 增加侧链采样
-ex1
-ex2aro

# 输出结构目录
-out:path:all output_files

# 可选：设置随机种子偏移
-seed_offset 12345
```

---

## 5. 运行 `run.sh`（这里是并行运行）

保存为 `run.sh` 文件：

```bash
#!/bin/bash

# 设置 Rosetta 可执行文件路径（请根据你的安装路径修改）
ROSETTA_BIN="/root/autodl-tmp/rosetta.binary.ubuntu.release-371/main/source/bin/docking_protocol.linuxgccrelease"

# flag 文件路径
FLAG_FILE="flag_global_docking"

# 总结构数和并行任务数
NSTRUCT_TOTAL=10000
N_JOBS=32
NSTRUCT_PER_JOB=$(( (NSTRUCT_TOTAL + N_JOBS - 1) / N_JOBS ))  # 向上取整

# 输出目录
OUTDIR="output_files"
mkdir -p "$OUTDIR"

# 设置统一的打分文件路径
SCOREFILE="${OUTDIR}/score.sc"

echo "启动 $N_JOBS 个 Rosetta docking 实例，每个生成 $NSTRUCT_PER_JOB 个结构..."
echo "所有输出结构和打分文件将保存在：$OUTDIR/"
echo "所有打分写入同一个文件：$SCOREFILE"

for i in $(seq 1 $N_JOBS); do
    $ROSETTA_BIN \
        @${FLAG_FILE} \
        -nstruct $NSTRUCT_PER_JOB \
        -out:suffix _global_dock_$i \
        -out:path:all $OUTDIR \
        -out:file:scorefile $SCOREFILE \
        > $OUTDIR/log_$i.txt 2>&1 &
    echo "启动任务 $i（输出结构后缀：_global_dock_$i）"
done

# 等待所有任务完成
wait
echo "所有 Rosetta docking 实例完成。结果保存在 $OUTDIR/"
```

## 6. 不知道为什么，可能是因为并行的原因，打分文件合并不到一起，因此这里用一个python脚本来从log里面提取分数

保存以下内容为 `tiqu.py`：

```python
import os
import re

# 设置日志文件目录
log_dir = "output_files"
output_score_file = os.path.join(log_dir, "parsed_scores.sc")

# 匹配 Rosetta 打分行的正则表达式（以 SCORE: 开头，后跟数字）
score_pattern = re.compile(r"^SCORE:\s+.*")

with open(output_score_file, "w") as outfile:
    header_written = False
    for filename in os.listdir(log_dir):
        if filename.startswith("log_") and filename.endswith(".txt"):
            filepath = os.path.join(log_dir, filename)
            with open(filepath, "r") as infile:
                for line in infile:
                    if score_pattern.match(line):
                        if not header_written and line.strip().startswith("SCORE:") and "total_score" in line:
                            outfile.write(line)
                            header_written = True
                        elif not line.strip().startswith("SCORE: total_score"):
                            outfile.write(line)

print(f"打分信息提取完成，保存至：{output_score_file}")
```

### 使用方法：

```bash
python tiqu.py
```

---

> 本脚本将自动从所有 `log_*.txt` 文件中提取包含 `SCORE:` 的打分行，并写入统一的打分文件 `parsed_scores.sc`  
> 请确保日志文件目录为 `output_files/`，或根据实际路径修改脚本中的 `log_dir` 变量。

---

## 📫 联系方式

如有错误，麻烦指出，谢谢！
如有问题，欢迎联系我。
youxiang：lijiawei_jn at yeah.net

---
